{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-04T23:41:14.553177700Z",
     "start_time": "2024-01-04T23:41:14.544152400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from src.config import settings\n",
    "from src.preparation import load_training_data\n",
    "from src.training import tokenize_and_prepare_labels"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Loading training data as a dataframe to see what it looks like\n",
    "training_data_df = pd.read_json(settings.TRAINING_DATA_FILE)\n",
    "training_data_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31f985d1d91d7561"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Loading base model an related tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T23:41:17.075129300Z",
     "start_time": "2024-01-04T23:41:14.549667900Z"
    }
   },
   "id": "db61ec8914639656",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/300 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a1467d4510b4de7b8d02b2d381a5b49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading training data as a list\n",
    "training_data = load_training_data()\n",
    "\n",
    "# Preparing training data and using the tokenizer to tokenize it\n",
    "dataset = Dataset.from_dict({\"text\": training_data})\n",
    "tokenized_dataset = dataset.map(tokenize_and_prepare_labels, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T23:41:17.090134800Z",
     "start_time": "2024-01-04T23:41:17.070129800Z"
    }
   },
   "id": "fca9973e362bb442",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Setting up training arguments and trainer\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir=settings.MODEL_FOLDER,\n",
    "\tnum_train_epochs=3,\n",
    "\tper_device_train_batch_size=2,\n",
    "\twarmup_steps=500,\n",
    "\tweight_decay=0.01,\n",
    "\tlogging_dir=settings.LOG_PATH,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "\tmodel=model,\n",
    "\targs=training_args,\n",
    "\ttrain_dataset=tokenized_dataset,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T23:41:17.091133900Z",
     "start_time": "2024-01-04T23:41:17.083129700Z"
    }
   },
   "id": "b27257fb2caf9359",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/450 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Running training\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-04T23:41:17.083129700Z"
    }
   },
   "id": "1588424f67cbc48"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Saving model and tokenizer\n",
    "model.save_pretrained(settings.MODEL_WEIGHT_PATH)\n",
    "tokenizer.save_pretrained(settings.MODEL_WEIGHT_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "47abd546370ab22b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
